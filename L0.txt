基数ペナルティを用いた完全補正ブースティング

abstract
明示的カーディナリティ正則化を用いた完全補正ブーストを提案する. 実際には新たな量子最適化技術によってスパースモデルができるようになるという希望が与えられたが, 存在する分類法を用いて組み合わせ最適化問題を効率的に解く方法は知られていない. アルゴリズムの有用性を実証するために, 分散型古典的ヒューリスティックオプティマイザを使用した. 古典的なコンピュータを用いて, この評価方法を行うと計算に大量な時間とリソースコストが発生するが,

1. introduction
ブーストアルゴリズムは各イタレーションに次の処理を行う(論文参照).  このアルゴリズムは与えられたm個の訓練例から分散uを提供する.いくつかの仮説クラスから弱い仮説を提供し, 分散を更新する. そして, 弱い仮説の線形結合w*を導き出す. ここでnはすべての弱い仮説のとりうる数である. ブースティングを行と列の間にゼロサムゲームとしてミスことができる. オラクルによって提供される各可能な仮説は, オラクルによって利用可能なすべての仮説クラスを表す基礎となるゲーム行列の列である. 訓練例はこの行列Hの列と一致する.  yHwは弱い仮説の線形結合wに関するラベルyとの距離を表す. 最適化の観点から, 正則化されたリスクの最小化を解くための行生成アプローチとして異なるプースティングアルゴリズムを見ることができる. 

(式1)

ここで, l()とΩ()は損失関数を表, 正則化は一般的に凸であると仮定する. Hの列の数は原則として無制限であるが, 実際は, すべての有限のデータセットに対して有限である. 
　有名なブースティングアルゴリズムでは正則化項としてl1ペナルティを選ぶのが一般的であり, したがって, w*の最適化はスパースとなることが期待できる. 実際, 良いブースティングアルゴリズムは理論的な証拠を示している. この点で, 是正ブースティングアルゴリズムと完全是正ブースティングアルゴリズム間の分散を作ることは価値がある. AdaBoostのような是正ブースティングアルゴリズムは各イタレーションごとにwの座標の一つだけを更新する. 一方で, ERLPBoostのような完全是正アルゴリズムでは各イタレーションですべてのアクティブな座標を更新する. すなわち, i回目のイタレーションでt次元の最適化問題を解く. 実験の結果より, 完全是正アルゴリズムは是正アルゴリズムと比較してかなりスパースな解を導いた. これより本稿の主問題を導くことができる.  アクティブな弱い仮説をできるだけ少なくして解を生成するために, l0擬似ノルムとしても知られているスパース誘導基数ペナルティ化(CP)を明示的に適用した場合はどうなるか. これは次の式を解く必要がある. 

(式2)

ここで, card(w)はwの非ゼロ要素の数を数え, 無視できるほど小さいがゼロではないvを持つL1項は, 不適切な最適化問題を回避する. 
 動機は二つある. 一つは, 商用的量子最適化技術の出現が近い将来にCPを含む問題を直接解くことが可能になることを期待している. 二つは, モバイル機器やウェアラブル機器からマイクドローンや深宇宙探索機に至るまで, リソースに制約のある環境で高精度の分度器を導入する必要がある. このようなアプリケーションでは, 待ち時間, 電力使用量および予測時のプロセッササイクルが非常に重要であるために, ブーストされたアンサンブルで基数ペナルティは突然実現可能な結果として不均衡な利益をもたらす可能性がある. 
　本稿では次のように整理する. 二章では背景を見直し, 三章ではではルジャンドル双対関数を導出することによってブーストに対するCPの影響を調べ, 次にTotalQBoostアルゴリズムについて説明する. 4,5,6章では実験の設定を示し, 結果をリストしてまとめる. 

2. 背景
Boosting: 一般的な正則化のリスクを最小として, すべての可能な列の空間Hデブースティング行う. ブーストアルゴリズムは原則として, 対応する主問題のラグランジュ双対を導き出して分析することができる条件ですべての顕在損失関数と正則化を組み込むことができる. ラグランジュ双対は列生成の考え方に密接に関係しているので, 論理的に扱う上で便利である. Demirizは, ブースティングについてのCGの見解を確立し, それを収束分析および結果として得られる実用的なアルゴリズムの終了基準の導出に使用する方法を示した. さらに, 強力な双対性が成り立つとき, 実用的な利益が見られる場合, アルゴリズム設計者は主問題よりも双対に最適化の負担をかけることを選ぶことができる. 正規化されたリスク最小化の観点ではブースティングとカーネルの方法の類似性が強調されている. Hからの弱い仮説の線形結合によるブーストもまた, 元のデータ特徴を高次元空間に効果的に描写し, それによって元の空間内に非線形決定面を構築することが可能になる. 
Cardinality penalization: 



[担当者氏名] 横田　知大
[論文情報（タイトル，著者，リンクなど）]  Totally Corrective Boosting with Cardinality Penalization
[論文の問題意識・扱う題材や課題]
[先行研究ではどのようなことがなされているか？(introなどを参照)]
[それら先行研究で不十分な部分はどこか？]
[その論文では，どこに焦点をあて，解決しようとしているか？]
[その解決のために，どのような考え・手法を導入したか？]
[その結果は？ 定量的に，もしくは定性的に，どのような点が改善されたか？] 
[（まだ残っている問題点は何か？）]

要約
Abstract
明示的な濃度正則化を用いた完全補正のブースティングアルゴリズムの提案. 
実験では量子ハードの代わりに分散型の古典的ヒューリスティックオプティマイザを使用した. 
古典的な計算機を使用したので多くの時間とリソースがかかった. 
実験にはブースティングアルゴリズムのベンチマークとして一般的に使用されるデータセットを利用し, 一般化パフォーマンスの向上と, ブーストされた平均結果のスパース性を用いて評価を行った. 
実験の結果, うまく動いた. 
また, 早期に停止する非正規化ブースティングアルゴリズムが凸正規化を行うものと比べて良い結果となる理由もわかった. 
以上のことから, 早期終了時に未解決のままになっている組み合わせ問題を明示的に解くことが有益であることがわかる. 

Introduction 
はじめにブースティングアルゴリズムについての説明を行っている. 
ブースティングアルゴリズムでは正則化項としてl1ペナルティを選ぶのが一般的なので, 最適解はスパースになる. 
是正ブースティングアルゴリズムは各イタレーションごとに座標の一つだけを更新するのに対し, 完全是正ブースティングアルゴリズムはすべての座標を更新する. 
完全是正ブースティングは是正アルゴリズムよりもスパースな解が得られる. 
アクティブな弱い仮説をできるだけ少なくして解を生成するために, L0の擬似ノルムとして知られているスパース誘導基数ペナルティ化(CP)を明示的に適用したものが(2)式になる. 
動機の一つは商用的な量子最適化技術が近い将来にCPを含む問題を直接解けるようにするため, もう一つは, リソースに制約のある環境で高精度の分類機を導入するため. 
二章では背景の見直し, 三章ではラグランジュ双対関数を導出することでブースティングに対するCPの影響を調べ, TotalQBoostアルゴリズムについて説明する. 
四五六章では実験の設定を示して結果をまとめる. 

2. 背景
ブースティング, 基数ペナルティ化, 量子最適化について説明をしている

3. CPを用いた完全是正ブースティング
3.1 ラグランジュ双対関数を分析した結果, CPがその影響を双対に伝播できないことがわかった. 
3.2 アルゴリズムを理解しやすくするために行生成についての詳細な説明をする. 
3.3 主問題のCP項によって生成される双対性のギャップを調べて, ブースティングアルゴリズムの設計のための洞察をする. 
3.4 早期停止をCPに関連付ける. 
3.5 連続変数を離散変数に変換することで発生する問題についての説明.

量子最適化ハードウェアは相互量子化された物理キュビットの集合として設計されているため、TotalQBoostはアルゴリズム1の10行目で離散重み変数wを使用します。これらはそれぞれ計算レベルでバイナリ変数と見なされます。現在のD-Waveハードウェアはたった約1000の機能的量子ビットを持っているので、wの各要素は、基礎となる量子ビットを使った2進展開によって離散変数を実装する固定小数点表現で少数のビットだけを使うように制限されます。連続変数から離散変数への変換から生じる実際的な問題は、連続変数で達成可能な最低の目的値で、またはそれに十分近い重み構成を表すことができなくなる可能性があることです。これに対する可能な解決策は、連続変数に対する最良の非CP経験的リスクが許容範囲内に達することができるまで、ビット深度を増やし続け、wの要素の範囲を調整し続けることです。その後、カーディナリティペナルティのある離散最適化を実行できます。しかしながら、必要なビット深度がそれほど高くないと予想されるとしても（Neven et al。、2012）、それでも、効果的に最適化するには大きすぎるバイナリ変数の総数をもたらす可能性があります。その場合、TotalQ-Boostが実行できる反復数Tは、当社の離散最適化機能のサイズによって制限されます。 wの変数が、列の最良のサブセットを正しく選択するのに十分なビット深度を持っていると仮定しても、l1正規化された経験的リスクを最小限に抑えるために選択列の重みを後で調整する機会があります。そのために、アルゴリズム1の12行目と13行目で指定されているように、CP選択列に対して、連続重み変数wを使用してL-BFGS-Bなどの既製の凸最適化アルゴリズムを実行します。

4. 実験設定
データセットごとに凸型CGの二つと基数ペナルティ付きCGの三つを比較する. 
A. L1正則化列生成法CG: 通常のL１正則化CG. 様々さ正則化係数を用いてε収束まで複数回実行して収束した集団の性能を記録する. 

B. 早期停止を伴う正規化されていないCG:  L1正則化CGだが, 無視できるほど小さいがゼロではない正則化係数を利用する. 分離可能なデータの場合は不適切な最適化問題を回避するためにゼロではない正則化係数が必要. 終了する基準に達する前に生成される列が多すぎる場合は早期停止が適用される. 異なる回数で早期に停止することの利点を評価するために最大反復回数Tまでに一回実行し, すべての中間の振る舞いを記録する. 

C. 是正ペナルティ付きCG: 無視できるほど小さいがゼロではないL1正則化係数と様々なCP係数を用いてTotalQBoostを適用し, 終了時の集合の性能を記録する. 弱い分類機の構造によっては, CPで主問題の大域的な最小値に達する前に有用な列を使い果たす可能性がある. このことから, 問題の最小値に達するという保証はないが, あらかじめ設定された反復回数Tに達したら早期停止する. 

D. ホットスタートCPCG: Cで到達する値よりも良いローカルミニマムになるようにするために行われる. 最初に早期停止UCGを実行し, これらのT列でCPCGを初期化しTotalQBoostに従って実行する. Cが同じλに対して生成する極小値とは異なる値をとる可能性がある. ここでも, 様々なCP係数に繰り返し行い, それぞれの終了後に性能を評価する. 

E. サブセット選択: Dの一段階で生成された列を取り, すべての異なる
Ｅ．サブセット選択：Ｄの第１段階で生成された列を取り、全ての異なるλ値について（３）に対応する一次ＲＭＰを一度だけ解き、得られたアンサンブルの性能を記録する。この実験は、λ値ごとに単一の離散最適化問題のみを解くので、ＣおよびＤよりも計算上安価である。目的は、Bによって生成されたアンサンブルの準最適性、およびDによって行われた追加の努力の価値を評価することです。

十分に大きな量子マシンがなかったの分散型ヒューリスティック手法を使用した. したがって, 是正ペナルティ付き最適化問題が適切に解かれたという保証がないことに注意する必要がある. 五つの実験の実際の比較において実験C〜Eの結果はおそらく適切ではない. 

それにもかかわらず、量子化最適化ハードウェアが機械学習の実践者に利用可能になるときはいつでも、ＣＥの結果に現れるどんな利点も確かにカーディナリティーペナルティの完全修正ブーストによってもたらされる潜在的な性能改善の証拠としてみなされる。

5. 結果
量子最適化ハードウェアの代わりとしてマルチスタートタブサーチを利用した. 是正ペナルティ付き最適化問題を解くときに最適性を保証することはできないがTabuアルゴリルズムに対して妥当な調整を行うことで, 解に対する基本的な信頼度を保証する. 

弱分類器の辞書は、それぞれが所定のデータセット内の元の特徴のうちの1つをとる決定スタンプの集合として構築されます。この研究では、CPの影響の研究に焦点を当てているので、損失関数の選択は重要ではありません。したがって、すべての実験で、ブースティングに最も一般的な損失関数である指数関数的損失を使用します。2L-BFGS-BおよびL1CGの終了に使用される最適化許容誤差εは、5×10 -4です。現在の最適化能力を超える大きな離散最適化問題を回避するために、別の終了基準が満たされない場合には、すべての方法の最大反復回数をT = 100に制限します。固定小数点離散変数wのビット深度は6として選択され、それらの範囲は、L-BFGS-B解に見られる連続変数wの最適値に基づいて、TotalQBoostの連続的な繰り返しにおいて暫定的に調整されます。実験ＤおよびＥのホットスタートカラムの数Ｔ 'は、付録Ｃに示すようにデータセットごとに選択される。

5.1 一般的なデータセットを用いた結果
ブースティングアルゴリズムのベンチマークに一般的に使用されている12の公開データセットについて、セクション4に記載されている実験を実行します。離散最適化のコストが高いため、1つのデータセットにつき80〜20％のトレイン検証分割を1回しか行うことができません。そのため、テスト結果を平均したものではありませんが、一般化の指標として検証セットで生成されたエラー率を提供します。結果の圧縮表示を図3に示します。実験ABとCEのうちの1つ以上が同じデータセットに対して同じ濃度を持つ分類子を生成する場合、モデルの選択が通常大規模な交差検証によってどのように行われるかのモックアップとして、パレート効率の原理に従ってグループ代表を選択し、L1CG / UCGとCPについてそれぞれ得られたパレートフロンティア（Kung et al。、1975）を描きます。

表1は、CPによって提供される最も注目すべき希薄化および一般化による利得のサンプリングを示しています。我々は、同等の一般化性能を有する最もまばらなＬ１ＣＧ ／ ＵＣＧ点に対するパレートフロンティア上のＣＰ点によって与えられる疎らさの改善として疎性利得を定義する。結果は、2.5％から67.65％の間のさまざまな希薄性の向上を示しています。疎性利得に関連するL1CG / UCG点がない、すなわちすべてのL1CG / UCG点が一般化性能を悪化させるときはいつでも、全体の最良のL1CG / UCG点に対するCP点によって与えられる一般化の改善として一般化利得を定量化する。すべて見た基数。結果は、0.95％から25％の間のさまざまな汎化効果を示しています。

Ｂに対する実験Ｅの最適化成功を比較するために、一致する濃度でＥがＢより悪い回数を数え、そしてＥおよびＢが一致する濃度を有する合計回数で割った。この測定では、経験的リスクについては1.61％、トレーニングエラーについては2.05％しか得られなかったため、早期停止の見方は単純に最適化されていないCPとして確認されました。経験的リスクについて、DはEから23.81％の時間で、トレーニングエラーで13.01％の時間で喪失した。これらの数字は主に、現時点では生成されたCP問題を完全かつ確実に最適化できないことに起因しています。


5.2 プロジェクトグラスでの結果
最後に、GoogleのProject Glassで使用されているアイジェスチャー検出器のブーストカスケードにも、CPの大きな影響がありました。 ウェアラブルデバイスは、厳しいメモリ、エネルギー、および処理上の制限を課すので、訓練された検出器は、任意の所望の検出精度で最大限にコンパクトであることが要求される。 早期停止による凸型ブースティングの修正版および完全修正版との比較では、〜105の例のトレーニングセットと〜104の特徴を使用した濃度〜20のカスケードでのCP最適化は固定リコールで15-45％誤検出を減らすことができます。

6 結論
歴史的には、AdaBoostと明示的に正規化されたブースティングアルゴリズムの比較では、 Duchi and Singer（2009）、我々がここでUCGと呼んでいるのは早期停止でL1CGより良い結果をもたらすことが知られている。 AdaBoostのような非常に単純化されたアルゴリズムがうまく機能している理由はやや謎ですが、カーディナリティーによるペナルティブーストのコンテキストでは、早期停止は準最適カーディナリティー正則化に他ならないと結論付けました。 明示的に濃度ペナルティを課されたCGを用いた我々の実験は、CPから生じる組み合わせ問題を解決しようと試みるので、著しい改善の余地があることを示している。 この研究では、量子ハードウェアの代わりに古典的な発見的アルゴリズムのみを使用したので、この学習アルゴリズムのための真に意図された最適化エンジンが広く利用可能になったときにどれほどはるかに良い結果が得られるかはまだわかりません。
